Meta VERSION="1" .
Job JOBID="job_201406230810_0003" JOBNAME="streamjob4410156423976698022\.jar" USER="cloudera" SUBMIT_TIME="1403831766144" JOBCONF="hdfs://localhost\.localdomain:8020/user/cloudera/\.staging/job_201406230810_0003/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201406230810_0003" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201406230810_0003" LAUNCH_TIME="1403831767451" TOTAL_MAPS="4" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201406230810_0003_m_000005" TASK_TYPE="SETUP" START_TIME="1403831767765" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201406230810_0003_m_000005" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000005_0" START_TIME="1403831771049" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201406230810_0003_m_000005" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403831796815" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(169649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(940)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108601344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(652959744)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000005" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1403831796960" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(169649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(940)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108601344)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(652959744)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201406230810_0003" JOB_STATUS="RUNNING" .
Task TASKID="task_201406230810_0003_m_000000" TASK_TYPE="MAP" START_TIME="1403831799466" SPLITS="/default/localhost\.localdomain" .
Task TASKID="task_201406230810_0003_m_000001" TASK_TYPE="MAP" START_TIME="1403831799474" SPLITS="/default/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000000" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000000_0" START_TIME="1403831799493" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000000" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403831879950" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="Records R/W\=791965/75344" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(283626)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1200770)][(MAP_OUTPUT_RECORDS)(Map output records)(114657)][(MAP_OUTPUT_BYTES)(Map output bytes)(2156493)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(114657)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13180)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(161525760)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217756)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1403831880219" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(283626)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1200770)][(MAP_OUTPUT_RECORDS)(Map output records)(114657)][(MAP_OUTPUT_BYTES)(Map output bytes)(2156493)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(114657)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13180)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(161525760)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217756)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000002" TASK_TYPE="MAP" START_TIME="1403831880240" SPLITS="/default/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000001" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000001_0" START_TIME="1403831799505" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000001" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403831880376" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="Records R/W\=741700/75154" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(286382)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1182208)][(MAP_OUTPUT_RECORDS)(Map output records)(117038)][(MAP_OUTPUT_BYTES)(Map output bytes)(2206478)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(117038)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13390)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(162652160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217723)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1403831880560" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(286382)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1182208)][(MAP_OUTPUT_RECORDS)(Map output records)(117038)][(MAP_OUTPUT_BYTES)(Map output bytes)(2206478)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(117038)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(13390)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(162652160)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217723)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000003" TASK_TYPE="MAP" START_TIME="1403831880596" SPLITS="/default/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000003" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000003_0" START_TIME="1403831880620" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000003" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403831948436" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="Records R/W\=727181/99777" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(294201)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(102288456)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(907067)][(MAP_OUTPUT_RECORDS)(Map output records)(124131)][(MAP_OUTPUT_BYTES)(Map output bytes)(2359275)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(124131)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(11970)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(156753920)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(102288341)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1403831948504" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(294201)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(102288456)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(907067)][(MAP_OUTPUT_RECORDS)(Map output records)(124131)][(MAP_OUTPUT_BYTES)(Map output bytes)(2359275)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(124131)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(11970)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(156753920)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(665706496)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(102288341)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000002" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000002_0" START_TIME="1403831880249" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201406230810_0003_m_000002" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403831951817" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="Records R/W\=1185022/146037" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(147282)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(464149)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1187798)][(MAP_OUTPUT_RECORDS)(Map output records)(146671)][(MAP_OUTPUT_BYTES)(Map output bytes)(2780933)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(293342)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(14070)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(160669696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(666353664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217712)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1403831951957" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(147282)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(464149)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(134283372)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1187798)][(MAP_OUTPUT_RECORDS)(Map output records)(146671)][(MAP_OUTPUT_BYTES)(Map output bytes)(2780933)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(293342)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(14070)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(160669696)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(666353664)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(110563328)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(134217712)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_r_000000" TASK_TYPE="REDUCE" START_TIME="1403831954425" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201406230810_0003_r_000000" TASK_ATTEMPT_ID="attempt_201406230810_0003_r_000000_0" START_TIME="1403831954434" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201406230810_0003_r_000000" TASK_ATTEMPT_ID="attempt_201406230810_0003_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1403831971569" SORT_FINISHED="1403831973158" FINISH_TIME="1403831983695" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="Records R/W\=502497/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(501688)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(671048)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1522)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(95)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(502352)][(REDUCE_INPUT_RECORDS)(Reduce input records)(502497)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(95)][(SPILLED_RECORDS)(Spilled Records)(502497)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8990)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108441600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(675655680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1403831983730" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(501688)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(671048)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1522)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(95)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(502352)][(REDUCE_INPUT_RECORDS)(Reduce input records)(502497)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(95)][(SPILLED_RECORDS)(Spilled Records)(502497)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8990)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108441600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(675655680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000004" TASK_TYPE="CLEANUP" START_TIME="1403831983746" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201406230810_0003_m_000004" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000004_0" START_TIME="1403831983765" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:58537" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201406230810_0003_m_000004" TASK_ATTEMPT_ID="attempt_201406230810_0003_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1403832001424" HOSTNAME="/default/localhost\.localdomain" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(169649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(470)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(93761536)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(655065088)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201406230810_0003_m_000004" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1403832001506" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(169649)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(470)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(93761536)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(655065088)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201406230810_0003" FINISH_TIME="1403832001512" JOB_STATUS="SUCCESS" FINISHED_MAPS="4" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(147282)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(1328358)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(505138572)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(8)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(502497)][(MAP_OUTPUT_BYTES)(Map output bytes)(9503179)][(SPLIT_RAW_BYTES)(Input split bytes)(432)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(649168)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(52610)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(641601536)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(2663473152)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(442253312)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(501688)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(671048)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1522)][(HDFS_READ_OPS)(HDFS: Number of read operations)(1)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(95)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(502352)][(REDUCE_INPUT_RECORDS)(Reduce input records)(502497)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(95)][(SPILLED_RECORDS)(Spilled Records)(502497)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(8990)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(108441600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(675655680)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(60751872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(648970)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(1999406)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(505138572)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(1522)][(HDFS_READ_OPS)(HDFS: Number of read operations)(9)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(4)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(4)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(344137)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(29261)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(4477843)][(MAP_OUTPUT_RECORDS)(Map output records)(502497)][(MAP_OUTPUT_BYTES)(Map output bytes)(9503179)][(SPLIT_RAW_BYTES)(Input split bytes)(432)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(95)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(502352)][(REDUCE_INPUT_RECORDS)(Reduce input records)(502497)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(95)][(SPILLED_RECORDS)(Spilled Records)(1151665)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(61600)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(750043136)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(3339128832)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(503005184)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(504941532)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
